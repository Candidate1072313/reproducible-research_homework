# Reproducible research: version control and R

1) Annotation of the **README.md** file of my logistic growth repository with more complete and detailed information about the analysis. (**10 points**)

   My work can be found **here**: https://github.com/Candidate1072313/logistic_growth/blob/main/README.md
   
2) Using my estimates to calculate the population size at 4980 minutes, assuming exponential growth. I will then compare this to the population size predicted under exponential growth. (**10 points**)

   My work can be found **here**: https://github.com/Candidate1072313/logistic_growth/blob/main/README.md
   
3) Addition of an R Script to my repository that compared the exponential and logistic growth curves. (**20 points**)

   My work can be found **here**: https://github.com/Candidate1072313/logistic_growth/blob/main/README.md

   My code and graph can be found **here**: https://github.com/Candidate1072313/logistic_growth/blob/main/exponential_logistic_comparison.R

4) Modelling Brownian motion. (**30 points**)

   a) Brownian motion defines the random movement of small particules suspended in fluid. A particle is in a state of **constant, random motion**, and is moving through space on a 'random walk'. This two-path code aims to use a reproducible process to generate the random walks of two particles through a fluid each time that it is executed. Data1 and Data2 gives the data for two different particles, and generate two different random walks - Plot1 and Plot2. There are 500 measurements for each particle, each of which is defined by its variables within space (given by x-coordinate and y-coordinate) and time (1-500 seconds). A random walk describes the random, stochastic motion of a particle that shows the probable location of a particle at a point in time, at which each 'step' is independent of previous and future ones. These random walks are generated by the dataframe, which sets aside the number of steps, minimum and maximum position of the particle, as well as its angle (defined by cosθh  and sinθh). Each time that this code is run, a new random walk of each of the particles is generated through both space and time. For example, this is one potential graph:
   
   ![image](https://github.com/user-attachments/assets/2304211a-3405-4af9-b55d-51c68638d410)

   b) The function **random seeds** in R can be used to randomly generate numbers. This would be important for modelling Brownian motion, since Brownian motion is defined by particles in a constant state of random motion throughout time and space. The randomness of numbers generated is important as it ensures that no numbers are dependent or related to each other. Random seeds can be used to ensure the **reproducibility** of the random set of numbers, since it is able to generate the same sequence of random outout numbers. Random seeds can often be used in conjunction with the **rnorm()** function, which allows sampling from a normal distribution. 

   c) My reproducible simulation of Brownian motion can be found **here**: https://github.com/Candidate1072313/reproducible-research_homework/blob/main/question-4-code/random_walk.R

   d) **Here** is my code edit in the comparison view:
   
      ![image](https://github.com/user-attachments/assets/93d04165-5490-4f84-8f14-0676ff84c5a9)

   
5) Predicting the size and volume of viral particles from their genome length, and modelling using relevant equations (**30 points**)

   a) This dataset has **33 rows** and **13 columns**

   b) For these data, we are modelling the genome length of viruses against viral volume, so it will be necessary to apply a data transformation to these variables. Since these data are so large, it will be necessary to perform a logarithmic transformation. This **logarithmic transformation** is also appropriate for the equation we are modelling, which is **$`V = αL^β `$**, which can also be modelled in a linear way, once they have been logarithmically transformed: **$` log(V) = βlog(L) + log(α)`$**

   c) Finding the values of the exponent $`β`$ and the scaling factor $`α`$ for dsDNA viruses 

     We can model our equation **$`V = αL^β `$** as a linear model, in the form **$` log(V) = βlog(L) + log(α)`$**, in which $`β`$ is the gradient of the line, and  $`log(α)`$ is the y-intercept.

     By running a linear model on our logarithmically transformed data data in the form `lmVirion <- lm(log_volume ~ log_genome, data = virionData2014)`, we find that the value of $`β`$ is $`1.5152`$, with a p-value of $`6.44 \times 10^{-10}`$

     The value of the Intercept, $`log(α)`$ is $`3.0725`$, with a p-value of $`2.28 \times 10^{-10}`$. However, this is not the true value of $`α`$, since it has been logarithmically transformed. As $`log_{10}α = 3.0725`$, then $`α = 1181.680313`$, or to put it more simply, $`α = 1.2\times 10^{3}`$, which appears to lie roughly at the point of intercept on the graph.

   **To summarise**:  $`β`$ is $`1.5152`$, with a p-value of $`6.44 \times 10^{-10}`$, and $`α = 1.2\times 10^{3}`$, with a p-value of $`2.28 \times 10^{-10}`$

   d)

   e) 
     

## Instructions

The homework for this Computer skills practical is divided into 5 questions for a total of 100 points. First, fork this repo and make sure your fork is made **Public** for marking. Answers should be added to the # INSERT ANSWERS HERE # section above in the **README.md** file of your forked repository.

Questions 1, 2 and 3 should be answered in the **README.md** file of the `logistic_growth` repo that you forked during the practical. To answer those questions here, simply include a link to your logistic_growth repo.

**Submission**: Please submit a single **PDF** file with your candidate number (and no other identifying information), and a link to your fork of the `reproducible-research_homework` repo with the completed answers (also make sure that your username has been anonymised). All answers should be on the `main` branch.

## Assignment questions 

1) (**10 points**) Annotate the **README.md** file in your `logistic_growth` repo with more detailed information about the analysis. Add a section on the results and include the estimates for $N_0$, $r$ and $K$ (mention which *.csv file you used).
   
2) (**10 points**) Use your estimates of $N_0$ and $r$ to calculate the population size at $t$ = 4980 min, assuming that the population grows exponentially. How does it compare to the population size predicted under logistic growth? 

3) (**20 points**) Add an R script to your repository that makes a graph comparing the exponential and logistic growth curves (using the same parameter estimates you found). Upload this graph to your repo and include it in the **README.md** file so it can be viewed in the repo homepage.
   
4) (**30 points**) Sometimes we are interested in modelling a process that involves randomness. A good example is Brownian motion. We will explore how to simulate a random process in a way that it is reproducible:

   a) A script for simulating a random_walk is provided in the `question-4-code` folder of this repo. Execute the code to produce the paths of two random walks. What do you observe? (10 points) \
   b) Investigate the term **random seeds**. What is a random seed and how does it work? (5 points) \
   c) Edit the script to make a reproducible simulation of Brownian motion. Commit the file and push it to your forked `reproducible-research_homework` repo. (10 points) \
   d) Go to your commit history and click on the latest commit. Show the edit you made to the code in the comparison view (add this image to the **README.md** of the fork). (5 points) 

5) (**30 points**) In 2014, Cui, Schlub and Holmes published an article in the *Journal of Virology* (doi: https://doi.org/10.1128/jvi.00362-14) showing that the size of viral particles, more specifically their volume, could be predicted from their genome size (length). They found that this relationship can be modelled using an allometric equation of the form **$`V = \alpha L^{\beta}`$**, where $`V`$ is the virion volume in nm<sup>3</sup> and $`L`$ is the genome length in nucleotides.

   a) Import the data for double-stranded DNA (dsDNA) viruses taken from the Supplementary Materials of the original paper into Posit Cloud (the csv file is in the `question-5-data` folder). How many rows and columns does the table have? (3 points)\
   b) What transformation can you use to fit a linear model to the data? Apply the transformation. (3 points) \
   c) Find the exponent ($\beta$) and scaling factor ($\alpha$) of the allometric law for dsDNA viruses and write the p-values from the model you obtained, are they statistically significant? Compare the values you found to those shown in **Table 2** of the paper, did you find the same values? (10 points) \
   d) Write the code to reproduce the figure shown below. (10 points) 

  <p align="center">
     <img src="https://github.com/josegabrielnb/reproducible-research_homework/blob/main/question-5-data/allometric_scaling.png" width="600" height="500">
  </p>

  e) What is the estimated volume of a 300 kb dsDNA virus? (4 points) 

   
